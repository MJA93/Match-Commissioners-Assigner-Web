import streamlit as st
import pandas as pd
import requests

# ---------------------------
# Page Configuration
# ---------------------------
st.set_page_config(page_title="Match Commissioners Assigner", page_icon="âš½", layout="wide")

# ---------------------------
# Sidebar Settings
# ---------------------------
st.sidebar.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
allow_same_day = st.sidebar.checkbox("Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¨Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ… (Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø¹Ø¨ ÙÙ‚Ø·)", value=True)
min_days_between = st.sidebar.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¨ÙŠÙ† Ø§Ù„ØªØ¹ÙŠÙŠÙ†Ø§Øª", value=2)
minimize_repeats = st.sidebar.checkbox("ØªÙ‚Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", value=True)
use_distance = st.sidebar.checkbox("Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Maps Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ©", value=False)
max_distance = st.sidebar.number_input("Ø£Ù‚ØµÙ‰ Ù…Ø³Ø§ÙØ© Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ±Ø§Øª", value=200)
google_api_key = st.sidebar.text_input("Google Maps API Key", type="password")

# ---------------------------
# File Uploads
# ---------------------------
st.title("ğŸ“„ ØªØ¹ÙŠÙŠÙ† Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ù„Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª")
st.markdown("**ğŸ”¼ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª ÙˆØ§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (Excel):**")

matches_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª", type=["xlsx"])
observers_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", type=["xlsx"])

# ---------------------------
# Helper: Google Maps API
# ---------------------------

def calculate_distance(city1, city2):
    if not (use_distance and google_api_key):
        return 0
    url = "https://maps.googleapis.com/maps/api/distancematrix/json"
    params = {
        "origins": city1,
        "destinations": city2,
        "key": google_api_key,
        "units": "metric",
        "language": "ar",
    }
    try:
        resp = requests.get(url, params=params).json()
        meters = resp["rows"][0]["elements"][0]["distance"]["value"]
        return meters / 1000  # ÙƒÙ…
    except Exception:
        return 1e9  # Ù‚ÙŠÙ…Ø© ÙƒØ¨ÙŠØ±Ø© ØªØ¹Ù†ÙŠ Ù…Ø³Ø§ÙØ© ØºÙŠØ± Ù…Ù‚Ø¨ÙˆÙ„Ø©

# ---------------------------
# Core Assigner
# ---------------------------

def assign_observers(matches, observers):
    assignments = []
    usage = {rid: 0 for rid in observers["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]}
    last_dates = {}

    for _, row in matches.iterrows():
        match_no = row["Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©"]
        if pd.isna(match_no):
            assignments.append("â€”")
            continue

        # ØªØ§Ø±ÙŠØ® (Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙŠÙˆÙ…)
        raw_date = str(row["Ø§Ù„ØªØ§Ø±ÙŠØ®"]).split("-")[-1].strip().split()[0]
        match_date = pd.to_datetime(raw_date, errors="coerce").date()
        city = str(row["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]).strip()
        stadium = str(row["Ø§Ù„Ù…Ù„Ø¹Ø¨"]).strip()

        # Ù…Ø±Ø´Ø­ÙŠÙ† Ø£ÙˆÙ„ÙŠÙŠÙ†
        cand = observers.copy()

        # Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ø­Ø³Ø¨ Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ… / Ø§Ù„Ù…Ù„Ø¹Ø¨
        def valid(o):
            rid = o["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            if rid in last_dates:
                d = last_dates[rid]
                if (match_date - d).days < min_days_between:
                    return False
                if not allow_same_day and d == match_date:
                    return False
            if use_distance:
                dist = calculate_distance(city, o["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"])
                if dist > max_distance:
                    return False
            return True

        cand = cand[cand.apply(valid, axis=1)]
        if minimize_repeats:
            cand = cand.sort_values(by=cand["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"].map(usage))

        if cand.empty:
            assignments.append("ØºÙŠØ± Ù…ØªÙˆÙØ±")
            continue

        chosen = cand.iloc[0]
        rid = chosen["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
        assignments.append(chosen["Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"])
        usage[rid] += 1
        last_dates[rid] = match_date

    matches["Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = assignments
    return matches

# ---------------------------
# Processing
# ---------------------------
if matches_file and observers_file:
    # 1) Read matches with dynamic columns
    matches_raw = pd.read_excel(matches_file)
    matches_raw.columns = matches_raw.columns.str.strip()
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª Unnamed
    def find_col(cols, keyword):
        return next(col for col in cols if keyword in str(col))

    cols = matches_raw.columns
    matches = matches_raw.rename(columns={
        find_col(cols, "Ø±Ù‚Ù…"): "Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©",
        find_col(cols, "Ø§Ø±ÙŠØ®"): "Ø§Ù„ØªØ§Ø±ÙŠØ®",
        find_col(cols, "Ù…Ù„Ø¹Ø¨"): "Ø§Ù„Ù…Ù„Ø¹Ø¨",
        find_col(cols, "Ù…Ø¯ÙŠÙ†"): "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©",
    })

    # 2) Read observers and clean columns
    obs_raw = pd.read_excel(observers_file)
    obs_raw.columns = obs_raw.columns.str.strip()

    obs_raw["Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"] = (
        obs_raw["Ø§Ù„Ø£Ø³Ù… Ø§Ù„Ø£ÙˆÙ„"].fillna("") + " " +
        obs_raw["Ø§Ù„Ø£Ø³Ù… Ø§Ù„Ø«Ø§Ù†ÙŠ"].fillna("") + " " +
        obs_raw["Ø£Ø³Ù… Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©"].fillna("")
    ).str.strip()

    obs_raw["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = obs_raw["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"].astype(str).str.strip()

    observers = obs_raw[["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨", "Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„", "Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]].dropna()

    st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­")

    if st.button("ğŸ”„ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ†"):
        result_df = assign_observers(matches, observers)
        st.success("âœ… ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ†")
        st.dataframe(result_df)
        st.download_button("ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", data=result_df.to_excel(index=False), file_name="assigned_matches.xlsx")
else:
    st.warning("ğŸ“Œ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ ÙƒÙ„Ø§ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ù„Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±.")
