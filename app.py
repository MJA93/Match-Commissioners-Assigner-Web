import streamlit as st
import pandas as pd
import requests
import re
from io import BytesIO
from functools import lru_cache
from datetime import datetime

st.set_page_config(page_title="Match Commissioners Assigner", page_icon="âš½", layout="wide")

# ---------------- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ---------------- #
st.sidebar.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
allow_same_day = st.sidebar.checkbox("Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¨Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ… (Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø¹Ø¨ ÙÙ‚Ø·)", value=True)
min_days_between = st.sidebar.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¨ÙŠÙ† Ø§Ù„ØªØ¹ÙŠÙŠÙ†Ø§Øª", min_value=0, value=2)
minimize_repeats = st.sidebar.checkbox("ØªÙ‚Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", value=True)
use_distance = st.sidebar.checkbox("Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Maps Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ©", value=True)
max_distance = st.sidebar.number_input("Ø£Ù‚ØµÙ‰ Ù…Ø³Ø§ÙØ© Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ±Ø§Øª", min_value=1, value=200)
google_api_key = st.sidebar.text_input("ğŸ”‘ Google Maps API", type="password")

# ---------------- ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ---------------- #
st.title("ğŸ“„ ØªØ¹ÙŠÙŠÙ† Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ù„Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª")
matches_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª", type="xlsx")
observers_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", type="xlsx")

# ---------------- Ø¯Ø§Ù„Ø© Ø§Ù„ØªØµØ­ÙŠØ­ ---------------- #
def correct_city(city):
    city = str(city).strip()
    return "Ø§Ù„Ù‡ÙÙˆÙ" if city == "Ø§Ù„Ø£Ø­Ø³Ø§Ø¡" else city

# ---------------- Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ø³Ø§ÙØ§Øª ---------------- #
@lru_cache(maxsize=10000)
def calculate_distance(city1, city2):
    if not (use_distance and google_api_key):
        return 0
    city1 = correct_city(city1)
    city2 = correct_city(city2)
    try:
        url = "https://maps.googleapis.com/maps/api/distancematrix/json"
        params = {
            "origins": city1,
            "destinations": city2,
            "key": google_api_key,
            "units": "metric",
            "language": "ar",
        }
        response = requests.get(url, params=params).json()
        meters = response["rows"][0]["elements"][0]["distance"]["value"]
        return meters / 1000
    except:
        return 1e9

# ---------------- Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª ---------------- #
def read_matches_file(file):
    try:
        df_raw = pd.read_excel(file, header=None)
        st.write("ğŸ“‹ Ø£ÙˆÙ„ 10 ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ù…Ù„Ù (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©):")
        st.dataframe(df_raw.head(10))

        header_row = None
        for i in range(len(df_raw)):
            if df_raw.iloc[i].astype(str).str.contains("Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©").any():
                header_row = i
                break

        if header_row is None:
            return None, "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©'."

        df = pd.read_excel(file, header=header_row)
        df.columns = df.columns.str.strip()

        if "Ø§Ù„ØªØ§Ø±ÙŠØ®" in df.columns:
            def clean_date(value):
                if isinstance(value, str):
                    value = re.sub(r"^\D+\s*[-â€“]?\s*", "", value.strip())
                    return pd.to_datetime(value, errors="coerce")
                return pd.to_datetime(value, errors="coerce")
            df["Ø§Ù„ØªØ§Ø±ÙŠØ®"] = df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].apply(clean_date)

        required_cols = ["Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ù…Ù„Ø¹Ø¨", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]
        if not all(col in df.columns for col in required_cols):
            return None, f"âš ï¸ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ©: {set(required_cols) - set(df.columns)}"

        df = df.dropna(subset=required_cols)
        if df.empty:
            return None, "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ."
        return df, None
    except Exception as e:
        return None, f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª: {e}"

# ---------------- Ø§Ù„ØªØ¹ÙŠÙŠÙ† ---------------- #
def assign_observers(matches, observers):
    assignments = []
    usage = {rid: 0 for rid in observers["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]}
    last_dates = {}

    progress = st.progress(0, text="ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ† ...")
    total = len(matches)

    for i, row in matches.iterrows():
        match_date = pd.to_datetime(row["Ø§Ù„ØªØ§Ø±ÙŠØ®"], errors="coerce").date()
        city = correct_city(row["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"])
        stadium = str(row["Ø§Ù„Ù…Ù„Ø¹Ø¨"]).strip()
        location = stadium if stadium else city

        candidates = observers.copy()

        def is_valid(obs):
            rid = obs["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            prev_date = last_dates.get(rid)

            if prev_date:
                if (match_date - prev_date).days < min_days_between:
                    return False
                if not allow_same_day and prev_date == match_date and obs["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] == city:
                    return False

            if use_distance:
                dist = calculate_distance(location, obs["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"])
                if dist > max_distance:
                    return False
            return True

        candidates = candidates[candidates.apply(is_valid, axis=1)]

        if minimize_repeats:
            candidates["Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†"] = candidates["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"].map(usage)
            candidates = candidates.sort_values(by="Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†")
            candidates = candidates.drop(columns=["Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†"])

        if candidates.empty:
            assignments.append(("ØºÙŠØ± Ù…ØªÙˆÙØ±", ""))
        else:
            selected = candidates.iloc[0]
            assignments.append((selected["Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"], selected["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]))
            rid = selected["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            usage[rid] += 1
            last_dates[rid] = match_date

        progress.progress((i + 1) / total, text=f"ğŸ”„ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ† ({i+1}/{total})")

    matches["Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = [x[0] for x in assignments]
    matches["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = [x[1] for x in assignments]
    return matches

# ---------------- Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---------------- #
matches = None
observers = None

if matches_file:
    matches, match_error = read_matches_file(matches_file)
    if match_error:
        st.warning(match_error)
        matches = None
    else:
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø¨Ù†Ø¬Ø§Ø­")

if observers_file:
    try:
        obs_raw = pd.read_excel(observers_file)
        obs_raw.columns = obs_raw.columns.str.strip()
        obs_raw["Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"] = (
            obs_raw["First name"].fillna("") + " " +
            obs_raw["2nd name"].fillna("") + " " +
            obs_raw["Family name"].fillna("")
        ).str.strip()
        obs_raw["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = obs_raw["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"].astype(str).str.strip()
        observers = obs_raw[["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨", "Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„", "Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]].dropna()
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ø¨Ù†Ø¬Ø§Ø­")
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†: {e}")
        observers = None

# ---------------- ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ† ---------------- #
if matches is not None and observers is not None:
    st.markdown("### âœ… Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ¹ÙŠÙŠÙ†")
    if st.button("ğŸ”„ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ†"):
        try:
            result = assign_observers(matches.copy(), observers)
            st.success("âœ… ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¨Ù†Ø¬Ø§Ø­")
            st.dataframe(result)

            output = BytesIO()
            result.to_excel(output, index=False, engine='openpyxl')
            st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", data=output.getvalue(), file_name="assigned_matches.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ†: {e}")
