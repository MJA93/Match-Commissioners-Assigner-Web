import streamlit as st
import pandas as pd
import requests
import re
import json
from io import BytesIO

st.set_page_config(page_title="Match Commissioners Assigner by Harashi", page_icon="âš½", layout="wide", initial_sidebar_state="expanded")

# ---------------------- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---------------------- #
st.sidebar.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
allow_same_day = st.sidebar.checkbox("Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¨Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ… (Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø¹Ø¨ ÙÙ‚Ø·)", value=True)
min_days_between = st.sidebar.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¨ÙŠÙ† Ø§Ù„ØªØ¹ÙŠÙŠÙ†Ø§Øª", value=2)
minimize_repeats = st.sidebar.checkbox("ØªÙ‚Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", value=True)
use_distance = st.sidebar.checkbox("Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Maps Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ©", value=True)
google_api_key = st.sidebar.text_input("Google Maps API Key", type="password")
max_distance = st.sidebar.number_input("Ø£Ù‚ØµÙ‰ Ù…Ø³Ø§ÙØ© Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ±Ø§Øª", value=200)

# ---------------------- ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ§Ø´ Ù„Ù„Ù…Ø³Ø§ÙØ§Øª ---------------------- #
try:
    with open("distance_cache.json", "r", encoding="utf-8") as f:
        distance_cache = json.load(f)
except:
    distance_cache = {}

# ---------------------- Google Maps Distance ---------------------- #
def google_maps_distance(city1, city2):
    url = "https://maps.googleapis.com/maps/api/distancematrix/json"
    params = {
        "origins": city1,
        "destinations": city2,
        "key": google_api_key,
        "units": "metric",
        "language": "ar"
    }
    response = requests.get(url, params=params)
    data = response.json()
    if data.get("status") != "OK":
        raise ValueError(f"API error: {data.get('status')}")
    element = data["rows"][0]["elements"][0]
    if element["status"] != "OK":
        raise ValueError(f"Element error: {element['status']}")
    return element["distance"]["value"] / 1000

@st.cache_data(show_spinner=False)
def calculate_distance(city1, city2):
    if city1 == city2:
        return 0
    key1 = f"{city1}|{city2}"
    key2 = f"{city2}|{city1}"

    if key1 in distance_cache:
        return distance_cache[key1]
    if key2 in distance_cache:
        return distance_cache[key2]

    try:
        dist = google_maps_distance(city1, city2)
        distance_cache[key1] = dist
        with open("distance_cache.json", "w", encoding="utf-8") as f:
            json.dump(distance_cache, f, ensure_ascii=False, indent=2)
        return dist
    except:
        distance_cache[key1] = 1e9
        with open("distance_cache.json", "w", encoding="utf-8") as f:
            json.dump(distance_cache, f, ensure_ascii=False, indent=2)
        return 1e9

# ---------------------- Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª ---------------------- #
def read_matches_file(file):
    try:
        df_raw = pd.read_excel(file, header=None)
        st.write("ğŸ“‹ Ø£ÙˆÙ„ 10 ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ù…Ù„Ù:")
        st.dataframe(df_raw.head(10))
        header_row = None
        for i in range(len(df_raw)):
            if df_raw.iloc[i].astype(str).str.contains("Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©").any():
                header_row = i
                break
        if header_row is None:
            return None, "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©'."
        df = pd.read_excel(file, header=header_row)
        df.columns = df.columns.str.strip()
        if "Ø§Ù„ØªØ§Ø±ÙŠØ®" in df.columns:
            def clean_date(value):
                if isinstance(value, str):
                    value = re.sub(r"^\D+\s*[-â€“]?\s*", "", value.strip())
                    return pd.to_datetime(value, errors="coerce")
                return pd.to_datetime(value, errors="coerce")
            df["Ø§Ù„ØªØ§Ø±ÙŠØ®"] = df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].apply(clean_date)
        required_cols = ["Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ù…Ù„Ø¹Ø¨", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]
        if not all(col in df.columns for col in required_cols):
            return None, f"âš ï¸ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ©: {set(required_cols) - set(df.columns)}"
        df = df.dropna(subset=required_cols)
        if df.empty:
            return None, "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ."
        return df, None
    except Exception as e:
        return None, f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª: {e}"

# ---------------------- Ø§Ù„ØªØ¹ÙŠÙŠÙ† ---------------------- #
def assign_observers(matches, observers):
    assignments = []
    usage = {rid: 0 for rid in observers["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]}
    last_dates = {}
    progress = st.progress(0, text="ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†...")
    for idx, row in matches.iterrows():
        match_date = pd.to_datetime(row["Ø§Ù„ØªØ§Ø±ÙŠØ®"], errors="coerce").date()
        city = str(row["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]).strip()
        stadium = str(row["Ø§Ù„Ù…Ù„Ø¹Ø¨"]).strip()
        candidates = observers.copy()
        def is_valid(obs):
            rid = obs["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            if rid in last_dates:
                prev_date = last_dates[rid]
                if (match_date - prev_date).days < min_days_between:
                    return False
                if not allow_same_day and prev_date == match_date and obs["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] == city:
                    return False
            if use_distance:
                dist = calculate_distance(city, obs["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"])
                if dist > max_distance:
                    return False
            return True
        candidates = candidates[candidates.apply(is_valid, axis=1)]
        if minimize_repeats:
            candidates["Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†"] = candidates["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"].map(usage)
            candidates = candidates.sort_values(by="Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†")
            candidates = candidates.drop(columns=["Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†"])
        if candidates.empty:
            assignments.append("ØºÙŠØ± Ù…ØªÙˆÙØ±")
        else:
            selected = candidates.iloc[0]
            assignments.append(f"{selected['Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„']}\n[{selected['Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨']}]")
            rid = selected["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            usage[rid] += 1
            last_dates[rid] = match_date
        progress.progress((idx + 1) / len(matches), text=f"ğŸ• Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹ÙŠÙŠÙ†... ({idx+1}/{len(matches)})")
    matches["Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = assignments
    return matches

# ---------------------- Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ---------------------- #
matches = None
observers = None

if matches_file:
    matches, match_error = read_matches_file(matches_file)
    if match_error:
        st.warning(match_error)
        matches = None
    else:
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø¨Ù†Ø¬Ø§Ø­")
        st.dataframe(matches.head())

if observers_file:
    try:
        obs_raw = pd.read_excel(observers_file)
        obs_raw.columns = obs_raw.columns.str.strip()
        obs_raw["Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"] = (
            obs_raw["First name"].fillna("") + " " +
            obs_raw["2nd name"].fillna("") + " " +
            obs_raw["Family name"].fillna("")
        ).str.strip()
        obs_raw["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = obs_raw["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"].astype(str).str.strip()
        observers = obs_raw[["\u0631\u0642\u0645 \u0627\u0644\u0645\u0631\u0627\u0642\u0628", "\u0627\u0644\u0627\u0633\u0645 \u0627\u0644\u0643\u0627\u0645\u0644", "\u0645\u062f\u064a\u0646\u0629 \u0627\u0644\u0645\u0631\u0627\u0642\u0628"]].dropna()
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ø¨Ù†Ø¬Ø§Ø­")
        st.dataframe(observers.head())
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†: {e}")
        observers = None

if matches is not None and observers is not None:
    st.markdown("### âœ… Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ¹ÙŠÙŠÙ†")
    if st.button("ğŸ”„ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ†"):
        try:
            result = assign_observers(matches.copy(), observers)
            st.success("âœ… ØªÙ… ØªÙ†ÙÙŠØ°
