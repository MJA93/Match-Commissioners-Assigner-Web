import streamlit as st
import pandas as pd
import requests
import datetime
import re
# ---------------------------
# Page Configuration
# ---------------------------
st.set_page_config(page_title="Match Commissioners Assigner", page_icon="âš½", layout="wide",initial_sidebar_state="expanded")

# ---------------------------
# Sidebar Settings
# ---------------------------
st.sidebar.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
allow_same_day = st.sidebar.checkbox("Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¨Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ… (Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø¹Ø¨ ÙÙ‚Ø·)", value=True)
min_days_between = st.sidebar.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¨ÙŠÙ† Ø§Ù„ØªØ¹ÙŠÙŠÙ†Ø§Øª", value=2)
minimize_repeats = st.sidebar.checkbox("ØªÙ‚Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", value=True)
use_distance = st.sidebar.checkbox("Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Maps Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ©", value=False)
max_distance = st.sidebar.number_input("Ø£Ù‚ØµÙ‰ Ù…Ø³Ø§ÙØ© Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ±Ø§Øª", value=200)
google_api_key = st.sidebar.text_input("Google Maps API Key", type="password")

# ---------------------------
# File Uploads
# ---------------------------
st.title("ğŸ“„ ØªØ¹ÙŠÙŠÙ† Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ù„Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª")
st.markdown("**ğŸ”¼ Ø±ÙØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª ÙˆØ§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ (Excel):**")

matches_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª", type=["xlsx"])
observers_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", type=["xlsx"])

# ---------------------------
# Helper: Google Maps API
# ---------------------------
def calculate_distance(city1, city2):
    if not (use_distance and google_api_key):
        return 0
    url = "https://maps.googleapis.com/maps/api/distancematrix/json"
    params = {
        "origins": city1,
        "destinations": city2,
        "key": google_api_key,
        "units": "metric",
        "language": "ar",
    }
    try:
        resp = requests.get(url, params=params).json()
        meters = resp["rows"][0]["elements"][0]["distance"]["value"]
        return meters / 1000
    except Exception:
        return 1e9

# ---------------------------
# Core Assigner
# ---------------------------
def assign_observers(matches, observers):
    assignments = []
    usage = {rid: 0 for rid in observers["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]}
    last_dates = {}

    for _, row in matches.iterrows():
        match_no = row["Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©"]
        if pd.isna(match_no):
            assignments.append("â€”")
            continue

        raw_date = str(row["Ø§Ù„ØªØ§Ø±ÙŠØ®"]).split()[0]  # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙŠÙˆÙ… Ù…Ù† Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ØªØ§Ø±ÙŠØ®
        match_date = pd.to_datetime(raw_date, errors="coerce").date()
        city = str(row["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]).strip()
        stadium = str(row["Ø§Ù„Ù…Ù„Ø¹Ø¨"]).strip()

        # Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ†
        cand = observers.copy()

        def valid(o):
            rid = o["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            if rid in last_dates:
                d = last_dates[rid]
                if (match_date - d).days < min_days_between:
                    return False
                if not allow_same_day and d == match_date and o["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] == city:
                    return False
            if use_distance:
                dist = calculate_distance(city, o["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"])
                if dist > max_distance:
                    return False
            return True

        cand = cand[cand.apply(valid, axis=1)]
        if minimize_repeats:
            cand = cand.sort_values(by=cand["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"].map(usage))

        if cand.empty:
            assignments.append("ØºÙŠØ± Ù…ØªÙˆÙØ±")
            continue

        chosen = cand.iloc[0]
        rid = chosen["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
        assignments.append(chosen["Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"])
        usage[rid] += 1
        last_dates[rid] = match_date

    matches["Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = assignments
    return matches

# ---------------------------
# File Handling
# ---------------------------
if matches_file and observers_file:
    try:
        matches_raw = pd.read_excel(matches_file, header=1)
        matches_raw.columns = matches_raw.columns.str.strip()
        cols = matches_raw.columns

        col_match_number = next((c for c in cols if "Ø±Ù‚Ù…" in c and "Ù…Ø¨Ø§Ø±Ø§Ø©" in c), None)
        col_match_date = next((c for c in cols if "ØªØ§Ø±ÙŠØ®" in c), None)
        col_stadium = next((c for c in cols if "Ù…Ù„Ø¹Ø¨" in c), None)
        col_city = next((c for c in cols if "Ù…Ø¯ÙŠÙ†Ø©" in c), None)

        if not all([col_match_number, col_match_date, col_stadium, col_city]):
            st.error(f"âš ï¸ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© Ø£Ùˆ ØºÙŠØ± ÙˆØ§Ø¶Ø­Ø©.
Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {list(cols)}")
        else:
            matches = matches_raw[[col_match_number, col_match_date, col_stadium, col_city]].dropna()

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªØ§Ø±ÙŠØ®
            def clean_date(value):
                if isinstance(value, str):
                    match = re.search(r"(\d{1,2}/\d{1,2}/\d{4})", value)
                    if match:
                        return pd.to_datetime(match.group(1), dayfirst=True)
                    return pd.NaT
                return pd.to_datetime(value, errors="coerce")

            matches[col_match_date] = matches[col_match_date].apply(clean_date)
            matches = matches.dropna(subset=[col_match_date])

            obs_raw = pd.read_excel(observers_file)
            obs_raw.columns = obs_raw.columns.str.strip()

            col_id = next((c for c in obs_raw.columns if "Ø±Ù‚Ù…" in c), None)
            col_first = next((c for c in obs_raw.columns if "first" in c.lower()), None)
            col_second = next((c for c in obs_raw.columns if "2nd" in c.lower()), None)
            col_family = next((c for c in obs_raw.columns if "family" in c.lower()), None)
            col_city_obs = next((c for c in obs_raw.columns if "Ù…Ø¯ÙŠÙ†Ø©" in c), None)

            if not all([col_id, col_first, col_family, col_city_obs]):
                st.error(f"âš ï¸ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©.
Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {list(obs_raw.columns)}")
            else:
                obs_raw["Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"] = (
                    obs_raw[col_first].fillna("") + " " +
                    obs_raw.get(col_second, "").fillna("") + " " +
                    obs_raw[col_family].fillna("")
                ).str.strip()
                obs_raw["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = obs_raw[col_city_obs].astype(str).str.strip()
                observers = obs_raw[[col_id, "Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„", "Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]].dropna()

                st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­")
                st.dataframe(matches.head())
                st.dataframe(observers.head())

    except Exception as e:
        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª: {e}")
else:
    st.warning("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ ÙƒÙ„Ø§ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ù„Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±.")

