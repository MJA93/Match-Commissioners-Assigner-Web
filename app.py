import streamlit as st
import pandas as pd
import requests
import re
from io import BytesIO
import hashlib

st.set_page_config(page_title="Match Commissioners Assigner", page_icon="âš½", layout="wide")

# ------------------ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ------------------ #
st.sidebar.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
allow_same_day = st.sidebar.checkbox("Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¨Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ…", value=True)
min_days_between = st.sidebar.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¨ÙŠÙ† Ø§Ù„ØªØ¹ÙŠÙŠÙ†Ø§Øª", value=2)
minimize_repeats = st.sidebar.checkbox("ØªÙ‚Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", value=True)
use_distance = st.sidebar.checkbox("Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Maps Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ©", value=True)
max_distance = st.sidebar.number_input("Ø£Ù‚ØµÙ‰ Ù…Ø³Ø§ÙØ© Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ±Ø§Øª", value=300)
google_api_key = st.sidebar.text_input("Google Maps API Key", type="password")

# ------------------ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ------------------ #
distance_cache = {}
def get_distance_cache_key(city1, city2):
    sorted_cities = tuple(sorted([city1.strip().lower(), city2.strip().lower()]))
    return hashlib.md5(str(sorted_cities).encode()).hexdigest()

def calculate_distance_with_cache(city1, city2):
    if not (use_distance and google_api_key):
        return 0
    cache_key = get_distance_cache_key(city1, city2)
    if cache_key in distance_cache:
        return distance_cache[cache_key]
    try:
        url = "https://maps.googleapis.com/maps/api/distancematrix/json"
        params = {
            "origins": city1,
            "destinations": city2,
            "key": google_api_key,
            "units": "metric",
            "language": "ar",
        }
        response = requests.get(url, params=params).json()
        meters = response["rows"][0]["elements"][0]["distance"]["value"]
        km = meters / 1000
        distance_cache[cache_key] = km
        return km
    except:
        distance_cache[cache_key] = 1e9
        return 1e9

# ------------------ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª ------------------ #
def read_matches_file(file):
    try:
        df_raw = pd.read_excel(file, header=None)
        st.write("ğŸ“‹ Ø£ÙˆÙ„ 10 ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ù…Ù„Ù:")
        st.dataframe(df_raw.head(10))
        header_row = None
        for i in range(len(df_raw)):
            if df_raw.iloc[i].astype(str).str.contains("Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©").any():
                header_row = i
                break
        if header_row is None:
            return None, "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙ ÙŠØ­ØªÙˆÙŠ 'Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©'."
        df = pd.read_excel(file, header=header_row)
        df.columns = df.columns.str.strip()
        if "Ø§Ù„ØªØ§Ø±ÙŠØ®" in df.columns:
            def clean_date(value):
                if isinstance(value, str):
                    value = re.sub(r"^\D+\s*[-â€“]?\s*", "", value.strip())
                    return pd.to_datetime(value, errors="coerce")
                return pd.to_datetime(value, errors="coerce")
            df["Ø§Ù„ØªØ§Ø±ÙŠØ®"] = df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].apply(clean_date)
        required_cols = ["Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ù…Ù„Ø¹Ø¨", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]
        if not all(col in df.columns for col in required_cols):
            return None, f"âš ï¸ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ©: {set(required_cols) - set(df.columns)}"
        df = df.dropna(subset=required_cols)
        if df.empty:
            return None, "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ."
        return df, None
    except Exception as e:
        return None, f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª: {e}"

# ------------------ Ø§Ù„ØªØ¹ÙŠÙŠÙ† ------------------ #
def assign_observers(matches, observers):
    assignments = []
    usage = {rid: 0 for rid in observers["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]}
    last_dates = {}

    progress_bar = st.progress(0)
    total_matches = len(matches)

    for idx, (_, row) in enumerate(matches.iterrows()):
        match_date = pd.to_datetime(row["Ø§Ù„ØªØ§Ø±ÙŠØ®"], errors="coerce").date()
        city = str(row["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]).strip()
        stadium = str(row["Ø§Ù„Ù…Ù„Ø¹Ø¨"]).strip()

        candidates = observers.copy()

        def is_valid(obs):
            rid = obs["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            if rid in last_dates:
                prev_date = last_dates[rid]
                if (match_date - prev_date).days < min_days_between:
                    return False
                if not allow_same_day and prev_date == match_date:
                    return False
            dist = calculate_distance_with_cache(city, obs["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"])
            if dist > max_distance:
                return False
            return True

        candidates = candidates[candidates.apply(is_valid, axis=1)]
        if minimize_repeats:
            candidates["Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†"] = candidates["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"].map(usage)
            candidates = candidates.sort_values(by="Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†")
            candidates = candidates.drop(columns=["Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†"])

        if candidates.empty:
            assignments.append("ØºÙŠØ± Ù…ØªÙˆÙØ±")
        else:
            selected = candidates.iloc[0]
            full_name = (
                selected["First name"].strip() + " " +
                selected["2nd name"].strip() + " " +
                selected["Family name"].strip()
            )
            assignments.append(f"{full_name} ({selected['Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨']})")
            rid = selected["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            usage[rid] += 1
            last_dates[rid] = match_date

        progress_bar.progress((idx + 1) / total_matches)

    matches["Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = assignments
    return matches

# ------------------ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ------------------ #
st.title("ğŸ“„ ØªØ¹ÙŠÙŠÙ† Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ù„Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª")

matches_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª", type=["xlsx"])
observers_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", type=["xlsx"])

matches = None
observers = None

if matches_file:
    matches, match_error = read_matches_file(matches_file)
    if match_error:
        st.warning(match_error)
        matches = None
    else:
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª")
        st.dataframe(matches.head())

if observers_file:
    try:
        obs = pd.read_excel(observers_file)
        obs.columns = obs.columns.str.strip()
        obs["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = obs["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"].astype(str).str.strip()
        obs["Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"] = (
            obs["First name"].fillna("") + " " +
            obs["2nd name"].fillna("") + " " +
            obs["Family name"].fillna("")
        ).str.strip()
        observers = obs[["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨", "First name", "2nd name", "Family name", "Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]].dropna()
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†")
        st.dataframe(observers.head())
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†: {e}")
        observers = None

if matches is not None and observers is not None:
    st.markdown("### âœ… Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ¹ÙŠÙŠÙ†")
    if st.button("ğŸ”„ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ†"):
        try:
            result = assign_observers(matches.copy(), observers)
            st.success("âœ… ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¨Ù†Ø¬Ø§Ø­")
            st.dataframe(result)
            output = BytesIO()
            result.to_excel(output, index=False, engine="openpyxl")
            st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù", data=output.getvalue(), file_name="assigned_matches.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¹ÙŠÙŠÙ†: {e}")
