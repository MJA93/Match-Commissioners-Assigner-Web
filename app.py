import streamlit as st
import pandas as pd
import requests
import re
import json
from io import BytesIO

st.set_page_config(page_title="Match Commissioners Assigner by Harashi", page_icon="âš½", layout="wide", initial_sidebar_state="expanded")

# ---------------------- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---------------------- #
st.sidebar.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
allow_same_day = st.sidebar.checkbox("Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¨Ù†ÙØ³ Ø§Ù„ÙŠÙˆÙ… (Ù†ÙØ³ Ø§Ù„Ù…Ù„Ø¹Ø¨ ÙÙ‚Ø·)", value=True)
min_days_between = st.sidebar.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø£ÙŠØ§Ù… Ø§Ù„Ø¯Ù†ÙŠØ§ Ø¨ÙŠÙ† Ø§Ù„ØªØ¹ÙŠÙŠÙ†Ø§Øª", value=2)
minimize_repeats = st.sidebar.checkbox("ØªÙ‚Ù„ÙŠÙ„ ØªÙƒØ±Ø§Ø± Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", value=True)
use_distance = st.sidebar.checkbox("Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenRouteService Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ©", value=True)
max_distance = st.sidebar.number_input("Ø£Ù‚ØµÙ‰ Ù…Ø³Ø§ÙØ© Ø¨Ø§Ù„ÙƒÙŠÙ„ÙˆÙ…ØªØ±Ø§Øª", value=200)

# ---------------------- Ù…ÙØªØ§Ø­ ORS ---------------------- #
ORS_API_KEY = "5b3ce3597851110001cf624808a520e10a8e4f9abbc780d99a908202"  # Ù…ÙØªØ§Ø­ Ù…Ø¤Ù‚Øª Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØºÙŠÙŠØ±

# ---------------------- Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ---------------------- #
st.title("ğŸ“„ ØªØ¹ÙŠÙŠÙ† Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ù„Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª")
matches_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª", type=["xlsx"])
observers_file = st.file_uploader("ğŸ“¥ Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†", type=["xlsx"])



# ---------------------- Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ORS + Cache ---------------------- #
@st.cache_data(show_spinner=False)
def load_city_lookup():
    try:
        df = pd.read_csv("cities_lookup.csv")
        return dict(zip(df["\u0627\u0644\u0627\u0633\u0645_\u0628\u0627\u0644\u0639\u0631\u0628\u064a"], df["\u0627\u0644\u0627\u0633\u0645_\u0627\u0644\u0645\u0648\u062d\u062f"]))
    except:
        return {}

city_lookup = load_city_lookup()

def calculate_distance(city1, city2):
    if city1 == city2:
        return 0

    city1_std = city_lookup.get(city1.strip(), city1.strip())
    city2_std = city_lookup.get(city2.strip(), city2.strip())

    try:
        with open("distance_cache.json", "r", encoding="utf-8") as f:
            cache = json.load(f)
    except:
        cache = {}

    key = f"{city1_std}|{city2_std}"
    if key in cache:
        return cache[key]

    try:
        url = "https://api.openrouteservice.org/v2/matrix/driving-car"
        headers = {
            'Authorization': ORS_API_KEY,
            'Content-Type': 'application/json'
        }
        
        def get_coords(city):
            geo = requests.get(
                f"https://api.openrouteservice.org/geocode/search?api_key={ORS_API_KEY}&text={city}&boundary.country=SA"
            ).json()
            coords = geo['features'][0]['geometry']['coordinates']
            return coords

        locations = [get_coords(city1_std), get_coords(city2_std)]

        body = {
            "locations": locations,
            "metrics": ["distance"],
            "units": "km"
        }

        response = requests.post(url, json=body, headers=headers).json()
        dist = response["distances"][0][1]

        cache[key] = dist
        with open("distance_cache.json", "w", encoding="utf-8") as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)

        return dist
    except:
        return 1e9


# ---------------------- Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª ---------------------- #
def read_matches_file(file):
    try:
        df_raw = pd.read_excel(file, header=None)
        st.write("ğŸ“‹ Ø£ÙˆÙ„ 10 ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ù…Ù„Ù:")
        st.dataframe(df_raw.head(10))

        header_row = None
        for i in range(len(df_raw)):
            if df_raw.iloc[i].astype(str).str.contains("Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©").any():
                header_row = i
                break

        if header_row is None:
            return None, "âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ØµÙ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 'Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©'."

        df = pd.read_excel(file, header=header_row)
        df.columns = df.columns.str.strip()

        if "Ø§Ù„ØªØ§Ø±ÙŠØ®" in df.columns:
            def clean_date(value):
                if isinstance(value, str):
                    value = re.sub(r"^\D+\s*[-â€“]?\s*", "", value.strip())
                    return pd.to_datetime(value, errors="coerce")
                return pd.to_datetime(value, errors="coerce")
            df["Ø§Ù„ØªØ§Ø±ÙŠØ®"] = df["Ø§Ù„ØªØ§Ø±ÙŠØ®"].apply(clean_date)

        required_cols = ["Ø±Ù‚Ù… Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©", "Ø§Ù„ØªØ§Ø±ÙŠØ®", "Ø§Ù„Ù…Ù„Ø¹Ø¨", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]
        if not all(col in df.columns for col in required_cols):
            return None, f"âš ï¸ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ©: {set(required_cols) - set(df.columns)}"

        df = df.dropna(subset=required_cols)
        if df.empty:
            return None, "âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ."
        return df, None

    except Exception as e:
        return None, f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª: {e}"

# ---------------------- Ø§Ù„ØªØ¹ÙŠÙŠÙ† ---------------------- #
def assign_observers(matches, observers):
    assignments = []
    usage = {rid: 0 for rid in observers["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]}
    last_dates = {}

    progress = st.progress(0, text="ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†...")

    for idx, row in matches.iterrows():
        match_date = pd.to_datetime(row["Ø§Ù„ØªØ§Ø±ÙŠØ®"], errors="coerce").date()
        city = str(row["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"]).strip()
        stadium = str(row["Ø§Ù„Ù…Ù„Ø¹Ø¨"]).strip()

        candidates = observers.copy()

        def is_valid(obs):
            rid = obs["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            if rid in last_dates:
                prev_date = last_dates[rid]
                if (match_date - prev_date).days < min_days_between:
                    return False
                if not allow_same_day and prev_date == match_date and obs["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] == city:
                    return False
            if use_distance:
                dist = calculate_distance(city, obs["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"])
                if dist > max_distance:
                    return False
            return True

        candidates = candidates[candidates.apply(is_valid, axis=1)]
        if minimize_repeats:
            candidates["Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†"] = candidates["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"].map(usage)
            candidates = candidates.sort_values(by="Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†")
            candidates = candidates.drop(columns=["Ù…Ø±Ø§Øª Ø§Ù„ØªØ¹ÙŠÙŠÙ†"])

        if candidates.empty:
            assignments.append("ØºÙŠØ± Ù…ØªÙˆÙØ±")
        else:
            selected = candidates.iloc[0]
            assignments.append(f"{selected['Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„']}\n[{selected['Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨']}]")
            rid = selected["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]
            usage[rid] += 1
            last_dates[rid] = match_date

        progress.progress((idx + 1) / len(matches), text=f"ğŸ• Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹ÙŠÙŠÙ†... ({idx+1}/{len(matches)})")

    matches["Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = assignments
    return matches

# ---------------------- Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ---------------------- #
matches = None
observers = None

if matches_file:
    matches, match_error = read_matches_file(matches_file)
    if match_error:
        st.warning(match_error)
        matches = None
    else:
        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù…Ø¨Ø§Ø±ÙŠØ§Øª Ø¨Ù†Ø¬Ø§Ø­")
        st.dataframe(matches.head())

if observers_file:
    try:
        obs_raw = pd.read_excel(observers_file)
        obs_raw.columns = obs_raw.columns.str.strip()

        # ØªØµØ­ÙŠØ­ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø§Ø³Ù…: Ø§Ù„Ø£ÙˆÙ„ + Ø§Ù„Ø«Ø§Ù†ÙŠ + Ø§Ù„Ø¹Ø§Ø¦Ù„Ø©
        obs_raw["Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"] = (
            obs_raw["First name"].fillna("") + " " +
            obs_raw["2nd name"].fillna("") + " " +
            obs_raw["Family name"].fillna("")
        ).str.strip()

        obs_raw["Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"] = obs_raw["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"].astype(str).str.strip()
        observers = obs_raw[["Ø±Ù‚Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨", "Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„", "Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨"]].dropna()

        st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ø¨Ù†Ø¬Ø§Ø­")
        st.dataframe(observers.head())

    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ†: {e}")
        observers = None

# ---------------------- ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ† ---------------------- #
if matches is not None and observers is not None:
    st.markdown("### âœ… Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ¹ÙŠÙŠÙ†")
    if st.button("ğŸ”„ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ†"):
        try:
            result = assign_observers(matches.copy(), observers)
            st.success("âœ… ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ† Ø¨Ù†Ø¬Ø§Ø­")
            st.dataframe(result)

            output = BytesIO()
            result.to_excel(output, index=False, engine='openpyxl')
            st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", data=output.getvalue(), file_name="assigned_matches.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ¹ÙŠÙŠÙ†: {e}")
