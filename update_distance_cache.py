
import pandas as pd
import requests
import json
import time
from itertools import product

ORS_API_KEY = "b3b1566c3b10xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ±Ø¬Ù…Ø© ÙˆØ§Ù„Ù…ØµØ¯Ø±
cities_df = pd.read_csv("cities_lookup.csv")
matches_df = pd.read_excel("matches_file.xlsx")
observers_df = pd.read_excel("observers_file.xlsx")

# Ø±Ø¨Ø· Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø¨Ø§Ù„Ù…ÙˆØ­Ø¯ (Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù…Ù‚Ø±ÙˆØ¡)
city_lookup = dict(zip(cities_df["Ø§Ù„Ø§Ø³Ù…_Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ"], cities_df["Ø§Ù„Ø§Ø³Ù…_Ø§Ù„Ù…ÙˆØ­Ø¯"]))

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¯Ù† Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª
match_cities = matches_df["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"].dropna().astype(str).str.strip().tolist()
observer_cities = observers_df["Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©"].dropna().astype(str).str.strip().tolist()
all_cities = sorted(set(match_cities + observer_cities))

# ØªØµÙÙŠØ© Ø§Ù„Ù…Ø¯Ù† ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©
translated_cities = [c for c in all_cities if c in city_lookup]
untranslated = [c for c in all_cities if c not in city_lookup]

if untranslated:
    print("âš ï¸ Ù…Ø¯Ù† Ù„Ù… ÙŠØªÙ… ØªØ±Ø¬Ù…ØªÙ‡Ø§ (Ø£Ø¶ÙÙ‡Ø§ Ù„Ù€ cities_lookup.csv):")
    for u in untranslated:
        print("-", u)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ø­Ø§Ù„ÙŠ
try:
    with open("distance_cache.json", "r", encoding="utf-8") as f:
        distance_cache = json.load(f)
except:
    distance_cache = {}

# Ø¯Ø§Ù„Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª
def get_coords(city):
    city_std = city_lookup.get(city, city)
    url = "https://api.openrouteservice.org/geocode/search"
    params = {
        "api_key": ORS_API_KEY,
        "text": city_std,
        "boundary.country": "SA"
    }
    r = requests.get(url, params=params)
    r.raise_for_status()
    geo = r.json()
    features = geo.get('features', [])
    if not features:
        return None
    return features[0]['geometry']['coordinates']

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙ‚Ø·
new_pairs = []
for c1, c2 in product(translated_cities, translated_cities):
    if c1 == c2:
        continue
    key1 = f"{c1}|{c2}"
    key2 = f"{c2}|{c1}"
    if key1 not in distance_cache and key2 not in distance_cache:
        new_pairs.append((c1, c2))

print(f"ğŸ” Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø²ÙˆØ§Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… Ø­Ø³Ø§Ø¨Ù‡Ø§: {len(new_pairs)}")

# Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
for idx, (city1, city2) in enumerate(new_pairs):
    try:
        coords1 = get_coords(city1)
        coords2 = get_coords(city2)

        if not coords1 or not coords2:
            raise ValueError("Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ù…ÙÙ‚ÙˆØ¯Ø©")

        matrix_url = "https://api.openrouteservice.org/v2/matrix/driving-car"
        headers = {
            "Authorization": ORS_API_KEY,
            "Content-Type": "application/json"
        }
        body = {
            "locations": [coords1, coords2],
            "metrics": ["distance"],
            "units": "km"
        }
        r = requests.post(matrix_url, json=body, headers=headers)
        r.raise_for_status()
        dist_data = r.json()
        dist = dist_data.get("distances", [[None, None]])[0][1]

        if dist is None:
            raise ValueError("Ø§Ù„Ù…Ø³Ø§ÙØ© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©")

        distance_cache[f"{city1}|{city2}"] = dist
        print(f"[{idx+1}/{len(new_pairs)}] {city1} <-> {city2} = {dist:.1f} km")

        if (idx + 1) % 100 == 0:
            with open("distance_cache.json", "w", encoding="utf-8") as f:
                json.dump(distance_cache, f, ensure_ascii=False, indent=2)

        time.sleep(1.2)

    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ {city1}|{city2}: {e}")
        continue

# Ø­ÙØ¸ Ù†Ù‡Ø§Ø¦ÙŠ
with open("distance_cache.json", "w", encoding="utf-8") as f:
    json.dump(distance_cache, f, ensure_ascii=False, indent=2)

print("\nâœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒØ§Ø´ Ø¨Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙ‚Ø·.")
